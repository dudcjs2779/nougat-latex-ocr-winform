{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dudcj\\OneDrive\\Desktop\\CodingTest\\C#\\Image_to_Latex\\Image_to_Latex\\bin\\Debug\\net6.0-windows\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# create: @time: 10/8/23 11:47\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "from transformers.models.nougat import NougatTokenizerFast\n",
    "from nougat_latex.util import process_raw_latex_code\n",
    "from nougat_latex import NougatLaTexProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\dudcj\\OneDrive\\Desktop\\CodingTest\\C#\\Image_to_Latex\\Image_to_Latex\\bin\\Debug\\net6.0-windows\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "c:\\Users\\dudcj\\OneDrive\\Desktop\\CodingTest\\C#\\Image_to_Latex\\Image_to_Latex\\bin\\Debug\\net6.0-windows\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\delta^{L}=\\left[\\delta_{1}^{L},\\delta_{2}^{L},\\cdots,\\delta_{j}^{L},\\cdots\\right]^{T}=\\left[\\frac{\\partial{\\cal C}}{\\partial a_{1}^{L}}\\cdot\\sigma^{\\prime}(z_{1}^{L}),\\frac{\\partial{\\cal C}}{\\partial a_{2}^{L}}\\cdot\\sigma^{\\prime}(z_{2}^{L}),\\cdots\\frac{\\partial{\\cal C}}{\\partial a_{j}^{L}}\\cdot\\sigma^{\\prime}(z_{j}^{L}),\\cdots\\right]^{T}\n"
     ]
    }
   ],
   "source": [
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser(prog=\"nougat inference config\", description=\"model archiver\")\n",
    "    parser.add_argument(\"--pretrained_model_name_or_path\", default=\"Norm/nougat-latex-base\")\n",
    "    parser.add_argument(\"--img_path\", help=\"path to latex image segment\", required=True)\n",
    "    parser.add_argument(\"--device\", default=\"gpu\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def run_nougat_latex():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model_name = 'Norm/nougat-latex-base'\n",
    "    imge_path = 'image/test01.png'\n",
    "\n",
    "    # init model\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    # init processor\n",
    "    tokenizer = NougatTokenizerFast.from_pretrained(model_name)\n",
    "    latex_processor = NougatLaTexProcessor.from_pretrained(model_name)\n",
    "\n",
    "    # run test\n",
    "    image = Image.open(imge_path)\n",
    "    if not image.mode == \"RGB\":\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    pixel_values = latex_processor(image, return_tensors=\"pt\").pixel_values\n",
    "    task_prompt = tokenizer.bos_token\n",
    "    decoder_input_ids = tokenizer(task_prompt, add_special_tokens=False,\n",
    "                                  return_tensors=\"pt\").input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            pixel_values.to(device),\n",
    "            decoder_input_ids=decoder_input_ids.to(device),\n",
    "            max_length=model.decoder.config.max_length,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "    sequence = tokenizer.batch_decode(outputs.sequences)[0]\n",
    "    sequence = sequence.replace(tokenizer.eos_token, \"\").replace(tokenizer.pad_token, \"\").replace(tokenizer.bos_token,\n",
    "                                                                                                  \"\")\n",
    "    sequence = process_raw_latex_code(sequence)\n",
    "    print(sequence)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_nougat_latex()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
